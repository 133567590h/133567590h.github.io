<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>hadoop(入门)</title>
    <link href="/2024/03/12/hadoop-%E5%85%A5%E9%97%A8/"/>
    <url>/2024/03/12/hadoop-%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<h1><a name="hadoop-" class="anchor" href="#hadoop-"><span class="header-link"></span></a>Hadoop(入门)</h1><h2><a name="1-" class="anchor" href="#1-"><span class="header-link"></span></a>1 大数据概述</h2><h3><a name="1-1-" class="anchor" href="#1-1-"><span class="header-link"></span></a>1.1 概述</h3><p>大数据（Big Data）：指无法在一定时间范围内用常规软件工具进行捕捉、管理和 处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化 能力的海量、高增长率和多样化的信息资产。</p><p><strong><em>大数据主要解决，海量数据的采集、存储和分析计算问题。</em></strong></p><p> 按顺序给出数据存储单位：bit、Byte、 KB、MB、GB、TB、PB、EB、ZB、YB、 BB、NB、DB。 </p><p>1Byte = 8bit 1K = 1024Byte 1MB = 1024K 1G = 1024M 1T = 1024G 1P = 1024T </p><h3><a name="1-2-" class="anchor" href="#1-2-"><span class="header-link"></span></a>1.2 特点</h3><ol><li><p>（<strong>Volume</strong>）大量</p><p>截至目前，人类生产的所有印刷材料的数据量是200PB，而历史上全人类总共 说过的话的数据量大约是5EB。当前，典型个人计算机硬盘的容量为TB量级，而 一些大企业的数据量已经接近EB量级。</p></li><li><p>（<strong>Velocity</strong>）高速</p><p>这是大数据区分于传统数据挖掘的最显著特征。根据IDC的“数字宇宙”的报 告，预计到2025年，全球数据使用量将达到163ZB。在如此海量的数据面前，处 理数据的效率就是企业的生命</p></li><li><p>（<strong>Variety</strong>）多样</p><p>这种类型的多样性也让数据被分为结构化数据和非结构化数据。相对于以往便于存储的 以数据库/文本为主的结构化数据，非结构化数据越来越多，包括网络日志、音频、视频、图 片、地理位置信息等，这些多类型的数据对数据的处理能力提出了更高要求</p></li><li><p>（<strong>Value</strong>）低价值密度</p><p>价值密度的高低与数据总量的大小成反比。</p><p><strong><em>它指的是在大量数据中真正有价值的信息往往只占很小的一部分，而大部分数据可能是噪声或者不相关的。因此，处理和分析大数据的一个关键挑战是如何从海量数据中提取出有用的信息。</em></strong></p></li><li><p>（<strong>Veracity</strong>）真实性</p><p>指大数据的质量，大数据的内容是与真实世界息息相关的，真实不一定代表准确，但一定不是虚假数据，这也是数据分析的基础。基于真实的交易与行为产生的数据，才有意义，如何Mock数据，是一个话题。如何识别造假数据，更是值得研究的领域。</p></li></ol><h3><a name="1-3-" class="anchor" href="#1-3-"><span class="header-link"></span></a>1.3 应用场景</h3><ul><li>抖音推荐</li><li>电商广告推荐</li><li>零售：分析用户消费习惯，为用户购买商品提供方便，从而提升商品销量。</li><li>物流仓储</li><li>保险</li><li>金融</li><li>房产</li><li>人工智能 + 5G + 物联网 + 虚拟与现实</li></ul><h3><a name="1-4-" class="anchor" href="#1-4-"><span class="header-link"></span></a>1.4 业务流程分析及内部组织结构</h3><h2><a name="2-hadoop-" class="anchor" href="#2-hadoop-"><span class="header-link"></span></a>2 Hadoop(入门)</h2><h3><a name="2-1-hadoop-" class="anchor" href="#2-1-hadoop-"><span class="header-link"></span></a>2.1 Hadoop概述</h3><h4><a name="2-1-1-hadoop" class="anchor" href="#2-1-1-hadoop"><span class="header-link"></span></a>2.1.1什么是hadoop</h4><p>1）Hadoop是一个由Apache基金会所开发的分布式系统基础架构。 </p><p>2）主要解决，海量数据的存储和海量数据的分析计算问题。</p><p> 3）广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈。</p><h4><a name="2-1-2-" class="anchor" href="#2-1-2-"><span class="header-link"></span></a>2.1.2发展历程</h4><p>查资料就行，了解，也是根据goole来的灵感</p><h4><a name="2-1-3-" class="anchor" href="#2-1-3-"><span class="header-link"></span></a>2.1.3三大发行版本</h4><p>Hadoop 三大发行版本：Apache、Cloudera、Hortonworks。 Apache 版本最原始（最基础）的版本，对于入门学习最好。2006 Cloudera 内部集成了很多大数据框架，对应产品 CDH。2008 Hortonworks 文档较好，对应产品 HDP。2011 Hortonworks 现在已经被 Cloudera 公司收购，推出新的品牌 CDP。</p><h4><a name="2-1-4hadoop-" class="anchor" href="#2-1-4hadoop-"><span class="header-link"></span></a>2.1.4hadoop优势</h4><p>1.高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元 素或存储出现故障，也不会导致数据的丢失。</p><p>2.高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。</p><p>3.高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处 理速度。</p><p>4.高容错性：能够自动将失败的任务重新分配</p><h4><a name="2-1-5hadoop-" class="anchor" href="#2-1-5hadoop-"><span class="header-link"></span></a>2.1.5hadoop组成</h4><p>在 Hadoop1.x 时 代 ， Hadoop中 的MapReduce同 时处理业务逻辑运算和资 源的调度，耦合性较大。 在Hadoop2.x时 代，增 加 了Yarn。Yarn只负责 资 源 的 调 度 ， MapReduce 只负责运算。 Hadoop3.x在组成上没 有变化。</p><h5><a name="2-1-5-1-hdfs" class="anchor" href="#2-1-5-1-hdfs"><span class="header-link"></span></a>2.1.5.1 HDFS</h5><p>Hadoop Distributed File System，简称 HDFS，是一个分布式文件系统。</p><p>HDFS架构概述</p><p>NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、 文件权限），以及每个文件的块列表和块所在的DataNode等。</p><p>DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。</p><p>Secondary NameNode(2nn)：每隔一段时间对NameNode元数据备份。</p><h5><a name="2-1-5-2-yarn" class="anchor" href="#2-1-5-2-yarn"><span class="header-link"></span></a>2.1.5.2 YARN</h5><p>Yet Another Resource Negotiator 简称 YARN ，另一种资源协调者，是 Hadoop 的资源管理器</p><p>YARN架构概述</p><p>ResourceManager（RM）：整个集群资源（内存、CPU等）的老大 </p><p>ApplicationMaster（AM）：单个任务运行的老大 </p><p>NodeManager（N M）：单个节点服务器资源老大 </p><p>Container：容器，相当一台独立的服务器，里面封装了 任务运行所需要的资源，如内存、CPU、磁盘、网络等。</p><p><strong><em>说明1：客户端可以有多个 说明2：集群上可以运行多个ApplicationMaster 说明3：每个NodeManager上可以有多个Container</em></strong></p><h5><a name="2-1-5-3-mapreduce" class="anchor" href="#2-1-5-3-mapreduce"><span class="header-link"></span></a>2.1.5.3 MapReduce</h5><p>MapReduce 将计算过程分为两个阶段：Map 和 Reduce</p><p>Map 阶段并行处理输入数据</p><p>Reduce 阶段对 Map 结果进行汇总</p><h5><a name="2-1-5-4-" class="anchor" href="#2-1-5-4-"><span class="header-link"></span></a>2.1.5.4 三者关系</h5><p><img src="/2024/03/12/hadoop-%E5%85%A5%E9%97%A8/image-20240311195245261-17102425186731.png" alt="image-20240311195245261"></p><h4><a name="2-1-6-" class="anchor" href="#2-1-6-"><span class="header-link"></span></a>2.1.6大数据技术生态体系</h4><h5><a name="-" class="anchor" href="#-"><span class="header-link"></span></a>推荐系统框架图</h5><p><img src="/2024/03/12/hadoop-%E5%85%A5%E9%97%A8/image-20240311195318640-17102425340403.png" alt="image-20240311195318640"></p><p>图中涉及的技术名词解释如下：</p><p> 1）Sqoop：Sqoop 是一款开源的工具，主要用于在 Hadoop、Hive 与传统的数据库（MySQL） 间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进 到 Hadoop 的 HDFS 中，也可以将 HDFS 的数据导进到关系型数据库中。</p><p> 2）Flume：Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统， Flume 支持在日志系统中定制各类数据发送方，用于收集数据；</p><p> 3）Kafka：Kafka 是一种高吞吐量的分布式发布订阅消息系统；</p><p>4）Spark：Spark 是当前最流行的开源大数据内存计算框架。可以基于 Hadoop 上存储的大数 据进行计算。</p><p> 5）Flink：Flink 是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。 </p><p>6）Oozie：Oozie 是一个管理 Hadoop 作业（job）的工作流程调度管理系统。</p><p> 7）Hbase：HBase 是一个分布式的、面向列的开源数据库。HBase 不同于一般的关系数据库， 它是一个适合于非结构化数据存储的数据库。 </p><p>8）Hive：Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张 数据库表，并提供简单的 SQL 查询功能，可以将 SQL 语句转换为 MapReduce 任务进行运 行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开 发专门的 MapReduce 应用，十分适合数据仓库的统计分析。</p><p> 9）ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、 名字服务、分布式同步、组服务等。</p><h2><a name="3-hadoop-" class="anchor" href="#3-hadoop-"><span class="header-link"></span></a>3 Hadoop 运行环境搭建（开发重点）</h2><h3><a name="3-1-strong-centos-7-5-x86-1804-strong-" class="anchor" href="#3-1-strong-centos-7-5-x86-1804-strong-"><span class="header-link"></span></a>3.1 模板虚拟机环境准备<strong>CentOS-7.5-x86-1804为例</strong></h3><h4><a name="3-1-1-" class="anchor" href="#3-1-1-"><span class="header-link"></span></a>3.1.1 基础准备</h4><p>安装好vm，并下载CentOS的镜像文件，创建一个虚拟机，配置好机器配置，完成好后，载入CentOS，启动！</p><p>上述涉及Linux的知识。见Linux的博客</p><h5><a name="3-1-1-1-" class="anchor" href="#3-1-1-1-"><span class="header-link"></span></a>3.1.1.1模板虚拟机准备</h5><p>完成开机后，需要将虚拟机设置为静态ip</p><p>1.首先进入命令行，输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim   /etc/sysconfig/network-scripts/ifcfg-ens33<br></code></pre></td></tr></table></figure><p>进入文件，按i进入编辑模式</p><p>修改并添加下列设置</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs vim">BOOTPROTO=<span class="hljs-string">&quot;static&quot;</span> <br>ONBOOT=<span class="hljs-string">&quot;yes&quot;</span>   #系统启动的时候网络接口是否有效（yes/<span class="hljs-keyword">no</span>）<br>#IP地址<br>IPADDR=<span class="hljs-number">192.168</span>.<span class="hljs-number">10.100</span>  <br>#网关  <br>GATEWAY=<span class="hljs-number">192.168</span>.<span class="hljs-number">10.2</span>      <br>#域名解析器<br>DNS1=<span class="hljs-number">192.168</span>.<span class="hljs-number">10.2</span><br>修改成自己的也行，但要保证<span class="hljs-number">168</span>后面的字段一致<br></code></pre></td></tr></table></figure><p>修改完后，按Esc 并输入:wq，保存并退出</p><p>2.接着输入</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">systemctl restart network<br></code></pre></td></tr></table></figure><p>重启网络服务。如果报错，则执行“reboot”命令，重启虚拟机</p><p>3.使用ifconfig命令查看当前IP</p><p>并查看ens33处ip是否为修改后的IPADDR</p><p>4.修改vm处的网络编辑器处vm8的网段相关信息与虚拟机一致。</p><h5><a name="3-1-1-2-hosts-" class="anchor" href="#3-1-1-2-hosts-"><span class="header-link"></span></a>3.1.1.2 修改主机名和hosts文件</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim /etc/hostname 修改为自己设置的主机名hadoop100<br></code></pre></td></tr></table></figure><p><strong>配置Linux</strong>克隆机主机名称映射hosts文件，打开/etc/hosts</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim /etc/hosts<br>并输入<br>192.168.10.100 hadoop100<br>192.168.10.101 hadoop101<br>192.168.10.102 hadoop102<br>192.168.10.103 hadoop103<br>192.168.10.104 hadoop104<br>192.168.10.105 hadoop105<br>192.168.10.106 hadoop106<br>192.168.10.107 hadoop107<br>192.168.10.108 hadoop108<br><br>完成后重启<br></code></pre></td></tr></table></figure><p><strong>修改windows</strong>的主机映射文件（host文件）</p><p>进入C:\Windows\System32\drivers\etc路径</p><p>打开hosts文件并添加如下内容，然后保存</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">192.168.10.100 hadoop100<br>192.168.10.101 hadoop101<br>192.168.10.102 hadoop102<br>192.168.10.103 hadoop103<br>192.168.10.104 hadoop104<br>192.168.10.105 hadoop105<br>192.168.10.106 hadoop106<br>192.168.10.107 hadoop107<br>192.168.10.108 hadoop108<br></code></pre></td></tr></table></figure><p>ps:如果是win10及以上则需另存后再覆盖</p><h4><a name="3-1-2-" class="anchor" href="#3-1-2-"><span class="header-link"></span></a>3.1.2 远程登录</h4><p>安装xshell并与模板机进行连接</p><p>完成上述准备工作</p><h3><a name="3-2-" class="anchor" href="#3-2-"><span class="header-link"></span></a>3.2虚拟机配置</h3><ol><li><p>安装epel-release</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum install -y epel-release<br>注意：如果Linux安装的是最小系统版，还需要安装如下工具；如果安装的是Linux桌面标准版，不需要执行如下操作<br>yum install -y net-tools <br>yum install -y vim<br></code></pre></td></tr></table></figure></li><li><p>关闭防火墙，关闭防火墙开机自启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">systemctl stop firewalld<br>systemctl disable firewalld.service<br>注意：在企业开发时，通常单个服务器的防火墙时关闭的。公司整体对外会设置非常安全的防火墙<br></code></pre></td></tr></table></figure></li><li><p>创建atguigu用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">useradd atguigu<br>passwd atguigu<br></code></pre></td></tr></table></figure><p>如果在创建虚拟机的时候已经创建用户，则跳过此步</p></li><li><p>配置atguigu</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim /etc/sudoers<br>修改/etc/sudoers文件，在%wheel这行下面添加一行，如下所示：<br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment"># Allow root to run any commands anywhere</span></span><br>root    ALL=(ALL)     ALL<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash"><span class="hljs-comment"># Allows people in group wheel to run all commands</span></span><br><span class="hljs-meta prompt_">%</span><span class="language-bash">wheel  ALL=(ALL)       ALL</span><br>atguigu   ALL=(ALL)     NOPASSWD:ALL<br>注意：atguigu这一行不要直接放到root行下面，因为所有用户都属于wheel组，你先配置了atguigu具有免密功能，但是程序执行到%wheel行时，该功能又被覆盖回需要密码。所以atguigu要放到%wheel这行下面。<br></code></pre></td></tr></table></figure></li><li><p>在/opt目录下创建文件夹，并修改所属主和所属组</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">在/opt目录下创建module、software文件夹<br>mkdir /opt/module<br>mkdir /opt/software<br>修改module、software文件夹的所有者和所属组均为atguigu用户 <br>chown atguigu:atguigu /opt/module <br>chown atguigu:atguigu /opt/software<br>查看module、software文件夹的所有者和所属组<br>cd /opt/<br>ll<br>drwxr-xr-x. 2 atguigu atguigu 4096 5月  28 17:18 module<br>drwxr-xr-x. 2 root    root    4096 9月   7 2017 rh<br>drwxr-xr-x. 2 atguigu atguigu 4096 5月  28 17:18 software<br></code></pre></td></tr></table></figure></li><li><p>卸载虚拟机自带的JDK</p><p>如果你的虚拟机是最小化安装不需要执行这一步。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps <br>rpm -qa：查询所安装的所有rpm软件包<br>grep -i：忽略大小写<br>xargs -n1：表示每次只传递一个参数<br>rpm -e –nodeps：强制卸载软件<br></code></pre></td></tr></table></figure></li><li><p>重启虚拟机</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">reboot<br></code></pre></td></tr></table></figure></li></ol><h3><a name="3-3-" class="anchor" href="#3-3-"><span class="header-link"></span></a>3.3 克隆虚拟机</h3><h4><a name="3-3-1-" class="anchor" href="#3-3-1-"><span class="header-link"></span></a>3.3.1克隆</h4><p><strong>利用模板机hadoop100</strong>，克隆三台虚拟机：hadoop102 hadoop103 hadoop104</p><p>注意：克隆时，要先关闭hadoop100</p><h4><a name="3-3-2-jdk" class="anchor" href="#3-3-2-jdk"><span class="header-link"></span></a>3.3.2安装JDK</h4><p>注意：安装JDK前，一定确保提前删除了虚拟机自带的JDK。</p><p><strong>用XShell</strong>传输工具将JDK<strong>导入到opt</strong>目录下面的software<strong>文件夹下面</strong></p><p>在 Linux 系统下的 opt 目录中查看软件包是否导入成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">ls /opt/software/<br></code></pre></td></tr></table></figure><p>解压 JDK 到/opt/module 目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/<br></code></pre></td></tr></table></figure><p>配置 JDK 环境变量</p><p>新建/etc/profile.d/my_env.sh 文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo vim /etc/profile.d/my_env.sh<br>添加如下内容<br><span class="hljs-meta prompt_">#</span><span class="language-bash">JAVA_HOME</span><br>export JAVA_HOME=/opt/module/jdk1.8.0_212<br>export PATH=$PATH:$JAVA_HOME/bin<br></code></pre></td></tr></table></figure><p>保存后退出</p><p>source 一下/etc/profile 文件，让新的环境变量 PATH 生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">source /etc/profile<br></code></pre></td></tr></table></figure><p>测试 JDK 是否安装成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">java -version<br>如果能看到以下结果，则代表 Java 安装成功。<br>java version &quot;1.8.0_212&quot;<br></code></pre></td></tr></table></figure><p>注意：重启（如果 java -version 可以用就不用重启）</p><h4><a name="3-3-3-hadoop102-hadoop" class="anchor" href="#3-3-3-hadoop102-hadoop"><span class="header-link"></span></a>3.3.3在hadoop102安装hadoop</h4><p>用 XShell 文件传输工具将 hadoop-3.1.3.tar.gz 导入到 opt 目录下面的 software 文件夹下面</p><p>进入到 Hadoop 安装包路径下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /opt/software/<br></code></pre></td></tr></table></figure><p>解压安装文件到/opt/module 下面</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">tar -zxvf hadoop-3.1.3.tar.gz -C <br>/opt/module/<br></code></pre></td></tr></table></figure><p>查看是否解压成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"> <span class="hljs-built_in">ls</span> /opt/module/<br>显示<br>hadoop-3.1.3<br></code></pre></td></tr></table></figure><p>将 Hadoop 添加到环境变量</p><p>打开/etc/profile.d/my_env.sh 文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo vim<br>/etc/profile.d/my_env.sh<br></code></pre></td></tr></table></figure><p>在 my_env.sh 文件末尾添加如下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">HADOOP_HOME</span><br>export HADOOP_HOME=/opt/module/hadoop-3.1.3<br>export PATH=$PATH:$HADOOP_HOME/bin<br>export PATH=$PATH:$HADOOP_HOME/sbin<br></code></pre></td></tr></table></figure><p>让修改后的文件生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">source /etc/profile<br></code></pre></td></tr></table></figure><p>测试是否安装成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">hadoop version<br>出现hadoop的版号<br></code></pre></td></tr></table></figure><p>重启（如果 Hadoop 命令不能用再重启虚拟机）</p><h3><a name="3-4-hadoop-" class="anchor" href="#3-4-hadoop-"><span class="header-link"></span></a>3.4 hadoop 目录结构</h3><p>查看 Hadoop 目录结构</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs shell">drwxr-xr-x. 2 atguigu atguigu 4096 5 月 22 2017 bin<br>drwxr-xr-x. 3 atguigu atguigu 4096 5 月 22 2017 etc<br>drwxr-xr-x. 2 atguigu atguigu 4096 5 月 22 2017 include<br>drwxr-xr-x. 3 atguigu atguigu 4096 5 月 22 2017 lib<br>drwxr-xr-x. 2 atguigu atguigu 4096 5 月 22 2017 libexec<br>-rw-r--r--. 1 atguigu atguigu 15429 5 月 22 2017 LICENSE.txt<br>-rw-r--r--. 1 atguigu atguigu 101 5 月 22 2017 NOTICE.txt<br>-rw-r--r--. 1 atguigu atguigu 1366 5 月 22 2017 README.txt<br>drwxr-xr-x. 2 atguigu atguigu 4096 5 月 22 2017 sbin<br>drwxr-xr-x. 4 atguigu atguigu 4096 5 月 22 2017 share<br></code></pre></td></tr></table></figure><p>（1）bin 目录：存放对 Hadoop 相关服务（hdfs，yarn，mapred）进行操作的脚本 </p><p>（2）etc 目录：Hadoop 的配置文件目录，存放 Hadoop 的配置文件 </p><p>（3）lib 目录：存放 Hadoop 的本地库（对数据进行压缩解压缩功能） </p><p>（4）sbin 目录：存放启动或停止 Hadoop 相关服务的脚本 </p><p>（5）share 目录：存放 Hadoop 的依赖 jar 包、文档、和官方案例</p><h2><a name="4-hadoop-" class="anchor" href="#4-hadoop-"><span class="header-link"></span></a>4 Hadoop 运行模式</h2><p>Hadoop 运行模式包括：本地模式、伪分布式模式以及完全分布式模式。</p><p>本地模式：单机运行，只是用来演示一下官方案例。生产环境不用。</p><p>伪分布式模式：也是单机运行，但是具备 Hadoop 集群的所有功能，一台服务器模 拟一个分布式的环境。个别缺钱的公司用来测试，生产环境不用。</p><p>完全分布式模式：多台服务器组成分布式环境。生产环境使用。</p><h3><a name="4-1-wordcount-" class="anchor" href="#4-1-wordcount-"><span class="header-link"></span></a>4.1本地运行模式（官方 WordCount）</h3><p>创建在 hadoop-3.1.3 文件下面创建一个 wcinput 文件夹</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir wcinput<br></code></pre></td></tr></table></figure><p>在 wcinput 文件下创建一个 word.txt 文件</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">cd</span> wcinput<br><span class="hljs-keyword">vim</span> word.txt<br>在文件中输入如下内容<br>hadoop yarn<br>hadoop mapreduce<br>atguigu<br>atguigu<br>保存退出<br></code></pre></td></tr></table></figure><p>回到 Hadoop 目录/opt/module/hadoop-3.1.3</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">hadoop jar <br>share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar <br>wordcount wcinput wcoutput<br></code></pre></td></tr></table></figure><p>查看结果</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">cat wcoutput/part-r-00000<br>看到如下结果：<br>atguigu 2<br>hadoop 2<br>mapreduce 1<br>yarn 1<br></code></pre></td></tr></table></figure><h3><a name="4-2-" class="anchor" href="#4-2-"><span class="header-link"></span></a>4.2 完全分布式运行模式（开发重点）</h3><p>1）准备 3 台客户机（关闭防火墙、静态 IP、主机名称）</p><p> 2）安装 JDK</p><p> 3）配置环境变量</p><p> 4）安装 Hadoop </p><p>5）配置环境变量</p><p> 6）配置集群</p><p>7）单点启动 </p><p>8）配置 ssh </p><p>9）群起并测试集群</p><p> 虚拟机准备,前面的章节，现在应该是拥有4台虚拟机Hadoop100 (模板机) ，hadoop102,hadoop103,hadoop104</p><h3><a name="4-2-1-xsync" class="anchor" href="#4-2-1-xsync"><span class="header-link"></span></a>4.2.1编写集群分发脚本 xsync</h3><h4><a name="4-2-1-1-scp-secure-copy-" class="anchor" href="#4-2-1-1-scp-secure-copy-"><span class="header-link"></span></a>4.2.1.1 scp（secure copy）安全拷贝</h4><p>（1）scp 定义 scp 可以实现服务器与服务器之间的数据拷贝。（from server1 to server2） </p><p>（2）基本语法</p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mel">scp -r $pdir/$fname $user@$host:$pdir/$fname  <br>命令 递归 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称<br></code></pre></td></tr></table></figure><p>（3）案例实操</p><p><strong>前提：在 hadoop102、hadoop103、hadoop104 都已经创建好的/opt/module、  /opt/software 两个目录，并且已经把这两个目录修改为 atguigu:atguigu</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo chown atguigu:atguigu -R /opt/module<br>（a）在 hadoop102 上，将 hadoop102 中/opt/module/jdk1.8.0_212 目录拷贝到hadoop103 上。<br>scp -r /opt/module/jdk1.8.0_212     atguigu@hadoop103:/opt/module<br><br>（b）在 hadoop103 上，将 hadoop102 中/opt/module/hadoop-3.1.3 目录拷贝到hadoop103 上。<br>scp -r  atguigu@hadoop102:/opt/module/hadoop-3.1.3   /opt/module/<br><br>（c）在 hadoop103 上操作，将 hadoop102 中/opt/module 目录下所有目录拷贝到hadoop104 上。<br>scp -r <br>atguigu@hadoop102:/opt/module/*<br>atguigu@hadoop104:/opt/module<br><br></code></pre></td></tr></table></figure><h4><a name="4-2-1-2-rsync-" class="anchor" href="#4-2-1-2-rsync-"><span class="header-link"></span></a>4.2.1.2 rsync 远程同步工具</h4><p>rsync 主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。 rsync 和 scp 区别：用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更 新。scp 是把所有文件都复制过去。</p><p>（1）基本语法 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">rsync -av $pdir/$fname $user@$host:$pdir/$fname <br>命令 选项参数 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称 <br>    选项参数说明:       选项 功能<br>                     -a 归档拷贝<br>                     -v 显示复制过程<br></code></pre></td></tr></table></figure><p>（2）案例实操</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell">（a）删除 hadoop103 中/opt/module/hadoop-3.1.3/wcinput<br> rm -rf wcinput/<br><br>（b）同步 hadoop102 中的/opt/module/hadoop-3.1.3 到 hadoop103<br>rsync -av hadoop-3.1.3/ <br>atguigu@hadoop103:/opt/module/hadoop-3.1.3/<br></code></pre></td></tr></table></figure><h4><a name="4-2-1-3-xsync-" class="anchor" href="#4-2-1-3-xsync-"><span class="header-link"></span></a>4.2.1.3 xsync 集群分发脚本</h4><p>（1）需求：循环复制文件到所有节点的相同目录下 </p><p>（2）需求分析： （a）rsync 命令原始拷贝： </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">rsync -av /opt/module atguigu@hadoop103:/opt/ <br></code></pre></td></tr></table></figure><p>（b）期望脚本： xsync 要同步的文件名称 </p><p>（c）期望脚本在任何路径都能使用（脚本放在声明了全局环境变量的路径） </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">echo $PATH /usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/atgu igu/.local/bin:/home/atguigu/bin:/opt/module/jdk1.8.0_212/bi n <br></code></pre></td></tr></table></figure><p>（3）脚本实现 </p><p>（a）在/home/atguigu/bin 目录下创建 xsync 文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs shell"> cd /home/atguigu <br> mkdir bin <br> cd bin <br> vim xsync<br> <br> 在该文件中编写如下代码 :<br><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/bash</span><br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">1. 判断参数个数</span><br>if [ $# -lt 1 ]<br>then<br>    echo Not Enough Arguement!<br>    exit;<br>fi<br><span class="hljs-meta prompt_">#</span><span class="language-bash">2. 遍历集群所有机器</span><br>for host in hadoop102 hadoop103 hadoop104<br>do<br>    echo ====================  $host  ====================<br>    #3. 遍历所有目录，挨个发送<br><br>    for file in $@<br>    do<br>        #4. 判断文件是否存在<br>        if [ -e $file ]<br>            then<br>                #5. 获取父目录<br>                pdir=$(cd -P $(dirname $file); pwd)<br><br>                #6. 获取当前文件的名称<br>                fname=$(basename $file)<br>                ssh $host &quot;mkdir -p $pdir&quot;<br>                rsync -av $pdir/$fname $host:$pdir<br>            else<br>                echo $file does not exists!<br>        fi<br>    done<br>done<br></code></pre></td></tr></table></figure><p>（b）修改脚本 xsync 具有执行权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">chmod +x xsync或 chmod 777 xsync<br></code></pre></td></tr></table></figure><p>（c）测试脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">xsync /home/atguigu/bin<br></code></pre></td></tr></table></figure><p>（d）将脚本复制到/bin中，以便全局调用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo cp xsync /bin/<br></code></pre></td></tr></table></figure><p>（e）同步环境变量配置（root所有者）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo ./bin/xsync /etc/profile.d/my_env.sh<br>注意：如果用了sudo，那么xsync一定要给它的路径补全。<br>让环境变量生效:在对应的另外两台机器上进行<br>source /etc/profile<br>source /etc/profile<br></code></pre></td></tr></table></figure><h3><a name="4-2-2-ssh-" class="anchor" href="#4-2-2-ssh-"><span class="header-link"></span></a>4.2.2 SSH无密登录配置</h3><p><strong>1）配置ssh</strong></p><p>（1）基本语法</p><p>ssh另一台电脑的IP地址</p><p>（2）ssh连接时出现Host key verification failed的解决方法</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">[atguigu@hadoop102 ~]$ ssh hadoop103<br>如果出现如下内容<br>Are you sure you want to continue connecting (yes/no)? <br>输入yes，并回车<br>进入到hadoop103<br></code></pre></td></tr></table></figure><p>（3）退回到hadoop102</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[atguigu@hadoop103 ~]$ exit<br></code></pre></td></tr></table></figure><p><strong>2）无密钥配置</strong></p><p>（1）免密登录原理</p><p>（2）生成公钥和私钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"> pwd<br>/home/atguigu/.ssh<br><br> ssh-keygen -t rsa<br><br>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）<br></code></pre></td></tr></table></figure><p>（3）将公钥拷贝到要免密登录的目标机器上</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs shell">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102<br>[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103<br>[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104<br>注意：<br>还需要在hadoop103上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。<br>还需要在hadoop104上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。<br>还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；<br>与上述命令相似<br></code></pre></td></tr></table></figure><p><strong>3）.ssh文件夹下（~/.ssh）的文件功能解释</strong></p><table><thead><tr><th>known_hosts</th><th>记录ssh访问过计算机的公钥（public  key）</th></tr></thead><tbody><tr><td>id_rsa</td><td>生成的私钥</td></tr><tr><td>id_rsa.pub</td><td>生成的公钥</td></tr><tr><td>authorized_keys</td><td>存放授权过的无密登录服务器公钥</td></tr></tbody></table><h3><a name="4-2-3-" class="anchor" href="#4-2-3-"><span class="header-link"></span></a>4.2.3 集群配置</h3><p><strong>1）集群部署规划</strong></p><p> <strong><em>NameNode和SecondaryNameNode不要安装在同一台服务器</em></strong></p><p><strong><em>ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</em></strong></p><table><thead><tr><th></th><th>hadoop102</th><th>hadoop103</th><th>hadoop104</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode  DataNode</td><td>DataNode</td><td>SecondaryNameNode  DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>ResourceManager  NodeManager</td><td>NodeManager</td></tr></tbody></table><p><strong>2）配置文件说明</strong></p><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p><p>（1）默认配置文件：</p><table><thead><tr><th>要获取的默认文件</th><th>文件存放在Hadoop的jar包中的位置</th></tr></thead><tbody><tr><td>[core-default.xml]</td><td>hadoop-common-3.1.3.jar/core-default.xml</td></tr><tr><td>[hdfs-default.xml]</td><td>hadoop-hdfs-3.1.3.jar/hdfs-default.xml</td></tr><tr><td>[yarn-default.xml]</td><td>hadoop-yarn-common-3.1.3.jar/yarn-default.xml</td></tr><tr><td>[mapred-default.xml]</td><td>hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml</td></tr></tbody></table><p>（2）自定义配置文件：</p><p>​    <strong>core-site.xml</strong>、<strong>hdfs-site.xml</strong>、<strong>yarn-site.xml</strong>、<strong>mapred-site.xml</strong>四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p><p><strong>3）配置集群</strong></p><p>（1）核心配置文件</p><p>配置core-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd $HADOOP_HOME/etc/hadoop<br>vim core-site.xml<br><br>文件内容如下：<br>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;<br>&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;<br><br>&lt;configuration&gt;<br>    &lt;!-- 指定NameNode的地址 --&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;fs.defaultFS&lt;/name&gt;<br>        &lt;value&gt;hdfs://hadoop102:8020&lt;/value&gt;<br>    &lt;/property&gt;<br><br>    &lt;!-- 指定hadoop数据的存储目录 --&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>        &lt;value&gt;/opt/module/hadoop-3.1.3/data&lt;/value&gt;<br>    &lt;/property&gt;<br><br>    &lt;!-- 配置HDFS网页登录使用的静态用户为atguigu --&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;<br>        &lt;value&gt;atguigu&lt;/value&gt;<br>    &lt;/property&gt;<br>&lt;/configuration&gt;<br><br></code></pre></td></tr></table></figure><p>（2）HDFS配置文件</p><p>配置hdfs-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim hdfs-site.xml<br>文件内容如下：<br>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;<br>&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;<br><br>&lt;configuration&gt;<br>&lt;!-- nn web端访问地址--&gt;<br>&lt;property&gt;<br>        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;<br>        &lt;value&gt;hadoop102:9870&lt;/value&gt;<br>    &lt;/property&gt;<br>&lt;!-- 2nn web端访问地址--&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;<br>        &lt;value&gt;hadoop104:9868&lt;/value&gt;<br>    &lt;/property&gt;<br>&lt;/configuration&gt;<br><br></code></pre></td></tr></table></figure><p>（3）YARN配置文件</p><p>配置yarn-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim yarn-site.xml<br>文件内容如下：<br>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;<br>&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;<br><br>&lt;configuration&gt;<br>    &lt;!-- 指定MR走shuffle --&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>    &lt;/property&gt;<br><br>    &lt;!-- 指定ResourceManager的地址--&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;<br>        &lt;value&gt;hadoop103&lt;/value&gt;<br>    &lt;/property&gt;<br><br>    &lt;!-- 环境变量的继承 --&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;<br>        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;<br>    &lt;/property&gt;<br>&lt;/configuration&gt;<br><br></code></pre></td></tr></table></figure><p>（4）MapReduce配置文件</p><p>配置mapred-site.xml</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs shell">vim mapred-site.xml<br>文件内容如下：<br>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;<br>&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;<br><br>&lt;configuration&gt;<br>&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;<br>    &lt;property&gt;<br>        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>        &lt;value&gt;yarn&lt;/value&gt;<br>    &lt;/property&gt;<br>&lt;/configuration&gt;<br><br></code></pre></td></tr></table></figure><p><strong>4）在集群上分发配置好的Hadoop配置文件</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">xsync /opt/module/hadoop-3.1.3/etc/hadoop/<br></code></pre></td></tr></table></figure><p><strong>5）去103和104上查看文件分发情况</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">[atguigu@hadoop103 ~]$ cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml<br>[atguigu@hadoop104 ~]$ cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml<br></code></pre></td></tr></table></figure><h3><a name="4-2-4-" class="anchor" href="#4-2-4-"><span class="header-link"></span></a>4.2.4 建起集群</h3><p><strong>1）配置workers</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">[atguigu@hadoop102 hadoop]$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers<br>在该文件中增加如下内容：<br>hadoop102<br>hadoop103<br>hadoop104<br>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。<br><br>同步所有节点配置文件<br>[atguigu@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc<br></code></pre></td></tr></table></figure><p><strong>2）启动集群</strong></p><p>（1）<strong>如果集群是第一次启动</strong>，需要在hadoop102节点格式化NameNode（<strong><em>注意：格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。</em></strong>）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[atguigu@hadoop102 hadoop-3.1.3]$ hdfs namenode -format<br></code></pre></td></tr></table></figure><p>（2）启动HDFS</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh<br></code></pre></td></tr></table></figure><p>（3）在配置了<strong>ResourceManager</strong>的节点（hadoop103）启动YARN</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">[atguigu@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh<br></code></pre></td></tr></table></figure><p> (4）Web端查看HDFS的NameNode</p><p>（a）浏览器中输入：<a href="http://hadoop102:9870">http://hadoop102:9870</a></p><p>（b）查看HDFS上存储的数据信息</p><p>  (5）Web端查看YARN的ResourceManager</p><p>（a）浏览器中输入：<a href="http://hadoop103:8088">http://hadoop103:8088</a></p><p>（b）查看YARN上运行的Job信息</p><p><strong>3）集群基本测试</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs shell">（1）上传文件到集群<br>上传小文件<br>[atguigu@hadoop102 ~]$ hadoop fs -mkdir /input<br>[atguigu@hadoop102 ~]$ hadoop fs -put $HADOOP_HOME/wcinput/word.txt /input<br><br>上传大文件<br>[atguigu@hadoop102 ~]$ hadoop fs -put  /opt/software/jdk-8u212-linux-x64.tar.gz  /<br><br>（2）上传文件后查看文件存放在什么位置<br>查看HDFS文件存储路径<br>[atguigu@hadoop102 subdir0]$ pwd<br>/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1436128598-192.168.10.102-1610603650062/current/finalized/subdir0/subdir0<br>查看HDFS在磁盘存储文件内容<br>[atguigu@hadoop102 subdir0]$ cat blk_1073741825<br>hadoop yarn<br>hadoop mapreduce <br>atguigu<br>atguigu<br><br>（3）拼接<br>-rw-rw-r--. 1 atguigu atguigu 134217728 5月  23 16:01 blk_1073741836<br>-rw-rw-r--. 1 atguigu atguigu   1048583 5月  23 16:01 blk_1073741836_1012.meta<br>-rw-rw-r--. 1 atguigu atguigu  63439959 5月  23 16:01 blk_1073741837<br>-rw-rw-r--. 1 atguigu atguigu    495635 5月  23 16:01 blk_1073741837_1013.meta<br><br>[atguigu@hadoop102 subdir0]$ cat blk_1073741836&gt;&gt;tmp.tar.gz<br>[atguigu@hadoop102 subdir0]$ cat blk_1073741837&gt;&gt;tmp.tar.gz<br>[atguigu@hadoop102 subdir0]$ tar -zxvf tmp.tar.gz<br><br>（4）下载<br>[atguigu@hadoop104 software]$ hadoop fs -get /jdk-8u212-linux-x64.tar.gz ./<br><br>（5）执行wordcount程序<br>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output<br></code></pre></td></tr></table></figure><h3><a name="4-2-5-" class="anchor" href="#4-2-5-"><span class="header-link"></span></a>4.2.5 配置历史服务器</h3><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs shell">1）配置mapred-site.xml<br>[atguigu@hadoop102 hadoop]$ vim mapred-site.xml<br>在该文件里面增加如下配置。<br>&lt;!-- 历史服务器端地址 --&gt;<br>&lt;property&gt;<br>    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;<br>    &lt;value&gt;hadoop102:10020&lt;/value&gt;<br>&lt;/property&gt;<br><br>&lt;!-- 历史服务器web端地址 --&gt;<br>&lt;property&gt;<br>    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;<br>    &lt;value&gt;hadoop102:19888&lt;/value&gt;<br>&lt;/property&gt;<br><br>2）分发配置<br>[atguigu@hadoop102 hadoop]$ xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml<br><br>3）在hadoop102启动历史服务器<br>[atguigu@hadoop102 hadoop]$ mapred --daemon start historyserver<br><br>4）查看历史服务器是否启动<br>[atguigu@hadoop102 hadoop]$ jps<br><br>5）查看JobHistory<br>http://hadoop102:19888/jobhistory<br></code></pre></td></tr></table></figure><h3><a name="4-2-6-" class="anchor" href="#4-2-6-"><span class="header-link"></span></a>4.2.6 配置日志的聚集</h3><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。</p><p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p><p><strong><em>注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryServer。</em></strong></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs xml">开启日志聚集功能具体步骤如下：<br>1）配置yarn-site.xml<br>[atguigu@hadoop102 hadoop]$ vim yarn-site.xml<br>在该文件里面增加如下配置。<br><span class="hljs-comment">&lt;!-- 开启日志聚集功能 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>  <br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log.server.url<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>  <br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>604800<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><br>2）分发配置<br>[atguigu@hadoop102 hadoop]$ xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml<br><br>3）关闭NodeManager 、ResourceManager和HistoryServer<br>[atguigu@hadoop103 hadoop-3.1.3]$ sbin/stop-yarn.sh<br>[atguigu@hadoop103 hadoop-3.1.3]$ mapred --daemon stop <br>historyserver<br><br>4）启动NodeManager 、ResourceManage和HistoryServer<br>[atguigu@hadoop103 ~]$ start-yarn.sh<br>[atguigu@hadoop102 ~]$ mapred --daemon start historyserver<br><br>5）删除HDFS上已经存在的输出文件<br>[atguigu@hadoop102 ~]$ hadoop fs -rm -r /output<br><br>6）执行WordCount程序<br>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output<br><br>7）查看日志<br>（1）历史服务器地址<br>http://hadoop102:19888/jobhistory<br></code></pre></td></tr></table></figure><h3><a name="4-2-7-" class="anchor" href="#4-2-7-"><span class="header-link"></span></a>4.2.7集群启动/停止方式总结</h3><p><strong>1）各个模块分开启动/停止（配置ssh是前提）常用</strong></p><p>​    （1）整体启动/停止HDFS</p><p>start-dfs.sh/stop-dfs.sh</p><p>​    （2）整体启动/停止YARN</p><p>start-yarn.sh/stop-yarn.sh</p><p><strong>2）各个服务组件逐一启动/停止</strong></p><p>​    （1）分别启动/停止HDFS组件</p><p>hdfs --daemon start/stop namenode/datanode/secondarynamenode</p><p>​    （2）启动/停止YARN</p><p>yarn --daemon start/stop resourcemanager/nodemanager</p><h4><a name="4-2-7-1-hadoop-" class="anchor" href="#4-2-7-1-hadoop-"><span class="header-link"></span></a>4.2.7.1编写Hadoop集群常用脚本</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs shell">1）Hadoop集群启停脚本（包含HDFS，Yarn，Historyserver）：myhadoop.sh<br>[atguigu@hadoop102 ~]$ cd /home/atguigu/bin<br>[atguigu@hadoop102 bin]$ vim myhadoop.sh<br>输入如下内容<br><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/bash</span><br><br>if [ $# -lt 1 ]<br>then<br>    echo &quot;No Args Input...&quot;<br>    exit ;<br>fi<br><br>case $1 in<br>&quot;start&quot;)<br>        echo &quot; =================== 启动 hadoop集群 ===================&quot;<br><br>        echo &quot; --------------- 启动 hdfs ---------------&quot;<br>        ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh&quot;<br>        echo &quot; --------------- 启动 yarn ---------------&quot;<br>        ssh hadoop103 &quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;<br>        echo &quot; --------------- 启动 historyserver ---------------&quot;<br>        ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver&quot;<br>;;<br>&quot;stop&quot;)<br>        echo &quot; =================== 关闭 hadoop集群 ===================&quot;<br><br>        echo &quot; --------------- 关闭 historyserver ---------------&quot;<br>        ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver&quot;<br>        echo &quot; --------------- 关闭 yarn ---------------&quot;<br>        ssh hadoop103 &quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot;<br>        echo &quot; --------------- 关闭 hdfs ---------------&quot;<br>        ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;<br>;;<br>*)<br>    echo &quot;Input Args Error...&quot;<br>;;<br>esac<br>保存后退出，然后赋予脚本执行权限<br>[atguigu@hadoop102 bin]$ chmod +x myhadoop.sh<br><br>2）查看三台服务器Java进程脚本：jpsall<br>[atguigu@hadoop102 ~]$ cd /home/atguigu/bin<br>[atguigu@hadoop102 bin]$ vim jpsall<br>输入如下内容<br><span class="hljs-meta prompt_">#</span><span class="language-bash">!/bin/bash</span><br><br>for host in hadoop102 hadoop103 hadoop104<br>do<br>        echo =============== $host ===============<br>        ssh $host jps <br>done<br>保存后退出，然后赋予脚本执行权限<br>[atguigu@hadoop102 bin]$ chmod +x jpsall<br><br>3）分发/home/atguigu/bin目录，保证自定义脚本在三台机器上都可以使用<br>[atguigu@hadoop102 ~]$ xsync /home/atguigu/bin/<br><br></code></pre></td></tr></table></figure><h3><a name="4-2-8-" class="anchor" href="#4-2-8-"><span class="header-link"></span></a>4.2.8 常用端口号说明</h3><table><thead><tr><th>端口名称</th><th>Hadoop2.x</th><th>Hadoop3.x</th></tr></thead><tbody><tr><td>NameNode内部通信端口</td><td>8020 / 9000</td><td>8020 /  9000/9820</td></tr><tr><td>NameNode HTTP UI</td><td>50070</td><td>9870</td></tr><tr><td>MapReduce查看执行任务端口</td><td>8088</td><td>8088</td></tr><tr><td>历史服务器通信端口</td><td>19888</td><td>19888</td></tr></tbody></table><h3><a name="4-2-9-" class="anchor" href="#4-2-9-"><span class="header-link"></span></a>4.2.9 集群时间同步</h3><p>如果服务器在公网环境（能连接外网），可以不采用集群时间同步，因为服务器会定期和公网时间进行校准；</p><p>如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步。</p><p><strong>1）需求</strong></p><p>找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，生产环境根据任务对时间的准确程度要求周期同步。测试环境为了尽快看到效果，采用1分钟同步一次。</p><p><strong>2）时间服务器配置（必须root用户）</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs shell">（1）查看所有节点ntpd服务状态和开机自启动状态<br>[atguigu@hadoop102 ~]$ sudo systemctl status ntpd<br>[atguigu@hadoop102 ~]$ sudo systemctl start ntpd<br>[atguigu@hadoop102 ~]$ sudo systemctl is-enabled ntpd<br><br><br>（2）修改hadoop102的ntp.conf配置文件<br>[atguigu@hadoop102 ~]$ sudo vim /etc/ntp.conf<br>修改内容如下<br>（a）修改1（授权192.168.10.0-192.168.10.255网段上的所有机器可以从这台机器上查询和同步时间）<br><span class="hljs-meta prompt_">#</span><span class="language-bash">restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</span><br>为restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap<br>（b）修改2（集群在局域网中，不使用其他互联网上的时间）<br>server 0.centos.pool.ntp.org iburst<br>server 1.centos.pool.ntp.org iburst<br>server 2.centos.pool.ntp.org iburst<br>server 3.centos.pool.ntp.org iburst<br>为<br><span class="hljs-meta prompt_">#</span><span class="language-bash">server 0.centos.pool.ntp.org iburst</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">server 1.centos.pool.ntp.org iburst</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">server 2.centos.pool.ntp.org iburst</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">server 3.centos.pool.ntp.org iburst</span><br>（c）添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）<br>server 127.127.1.0<br>fudge 127.127.1.0 stratum 10<br><br><br>（3）修改hadoop102的/etc/sysconfig/ntpd 文件<br>[atguigu@hadoop102 ~]$ sudo vim /etc/sysconfig/ntpd<br>增加内容如下（让硬件时间与系统时间一起同步）<br>SYNC_HWCLOCK=yes<br><br><br>（4）重新启动ntpd服务<br>[atguigu@hadoop102 ~]$ sudo systemctl start ntpd<br><br><br>（5）设置ntpd服务开机启动<br>[atguigu@hadoop102 ~]$ sudo systemctl enable ntpd<br></code></pre></td></tr></table></figure><p><strong>3）其他机器配置（必须root用户）</strong></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs shell">（1）关闭所有节点上ntp服务和自启动<br>[atguigu@hadoop103 ~]$ sudo systemctl stop ntpd<br>[atguigu@hadoop103 ~]$ sudo systemctl disable ntpd<br>[atguigu@hadoop104 ~]$ sudo systemctl stop ntpd<br>[atguigu@hadoop104 ~]$ sudo systemctl disable ntpd<br><br>（2）在其他机器配置1分钟与时间服务器同步一次<br>[atguigu@hadoop103 ~]$ sudo crontab -e<br>编写定时任务如下：<br>*/1 * * * * /usr/sbin/ntpdate hadoop102<br><br>（3）修改任意机器时间<br>[atguigu@hadoop103 ~]$ sudo date -s &quot;2021-9-11 11:11:11&quot;<br>（4）1分钟后查看机器是否与时间服务器同步<br>[atguigu@hadoop103 ~]$ sudo date<br></code></pre></td></tr></table></figure><h2><a name="5-" class="anchor" href="#5-"><span class="header-link"></span></a>5 常见错误及解决方案</h2><p>1）防火墙没关闭、或者没有启动YARN</p><p><em>INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032</em></p><p>2）主机名称配置错误</p><p>3）IP地址配置错误</p><p>4）ssh没有配置好</p><p>5）root用户和atguigu两个用户启动集群不统一</p><p>6）配置文件修改不细心</p><p>7）不识别主机名称</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java">java.net.UnknownHostException: hadoop102: hadoop102<br>        at java.net.InetAddress.getLocalHost(InetAddress.java:<span class="hljs-number">1475</span>)<br>        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:<span class="hljs-number">146</span>)<br>        at org.apache.hadoop.mapreduce.Job$<span class="hljs-number">10.</span>run(Job.java:<span class="hljs-number">1290</span>)<br>        at org.apache.hadoop.mapreduce.Job$<span class="hljs-number">10.</span>run(Job.java:<span class="hljs-number">1287</span>)<br>        at java.security.AccessController.doPrivileged(Native Method)<br>at javax.security.auth.Subject.doAs(Subject.java:<span class="hljs-number">415</span>)<br><br></code></pre></td></tr></table></figure><p>解决办法：</p><p>（1）在/etc/hosts文件中添加192.168.10.102 hadoop102</p><p>​    （2）主机名称不要起hadoop hadoop000等特殊名称</p><p>8）DataNode和NameNode进程同时只能工作一个。</p><p>9）执行命令不生效，粘贴Word中命令时，遇到-和长–没区分开。导致命令失效</p><p>解决办法：尽量不要粘贴Word中代码。</p><p>10）jps发现进程已经没有，但是重新启动集群，提示进程已经开启。</p><p>原因是在Linux的根目录下/tmp目录中存在启动的进程临时文件，将集群相关进程删除掉，再重新启动集群。</p><p>11）jps不生效</p><p>原因：全局变量hadoop java没有生效。解决办法：需要source /etc/profile文件。</p><p>12）8088端口连接不上</p><p>[atguigu@hadoop102 桌面]$ cat /etc/hosts</p><p>注释掉如下代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="hljs-meta prompt_">#</span><span class="language-bash">::1         hadoop102</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>大数据</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大数据</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>漫谈</title>
    <link href="/2023/12/23/%E6%BC%AB%E8%B0%881/"/>
    <url>/2023/12/23/%E6%BC%AB%E8%B0%881/</url>
    
    <content type="html"><![CDATA[<h1><a name="-" class="anchor" href="#-"><span class="header-link"></span></a>话在前头</h1><p>说实在话有点不想重写了毕竟也是写了一个月的存稿全没了，(⓿_⓿)。但再三考虑后还是选择重开。所以之后更新的话应该是慢一些，但寒假<strong>肯定应该无误的话</strong>是每天一篇的更新速度（鸽了的话，我就咕咕咕吧）。也算吸取了之前的教训：首先不纠结博客的主题，然后把内容啥的做好。所以欢迎你们来访问。</p><p>———————————————————————————————————</p><p><del>手动分割线</del></p><p>​    今天开始考研了，先祝各位考生成功上岸（￣︶￣）↗<img src="/2023/12/23/%E6%BC%AB%E8%B0%881/20220624101347_d2d95.jpg" alt></p><p>​    当然今年考研的人数下降了不少，反之就是考公的人数增大了。不禁让人想象将来自己的样子，这个问题也是咱们许多人想过的吧。对于我来说马上要步入2开头的年龄了，<del>啊！~岁月催人老啊</del>(。・ω・。)。我的经历应该算不平不淡的，既没有很好的成果，也没有很坏的历史，经典的“好孩子”的样子，可能自己是什么样的都不知道。</p><p>​    在这之前我要感谢我的父母，虽然他们对我的应试教育这一块可能是相对失败的，但在有育人这一块是给了我很正的观念。我永远记得老妈对我说的话“要活出你自己的样子”。之前小时候缺少爱吧，所以我应该算缺失爱的那种孩子，外加父母小时候也算经常吵架的，所以导致我的性格算那种有点自卑，又有点内向但会照顾人(哈哈说简单点会看脸色)的那种。所以做人这个方面应该算做得还好的那种，所以能很幸运能遇到几个兄弟，知己最难遇。对待身边的人也是包容为主的样子，基本我不会生气，虽然自己的表情不是很好是真的ψ(｀∇´)ψ。但沟通上我基本不会怎么沟通，觉得不知怎么能有效沟通，所以能遇上知己兄弟就很难得了。这是做人方面吧，还算过得去。</p><p>​    但在学业这一块，应该算我自己的问题，我坚持一件事怎么说呢能坚持但也容易被干扰(<del>从未体会过自律</del>)，外界的诱惑等等，当然这是作为一个人的缺陷，可以说是与生俱来的。所以能从小到大，我之所以能取得一个较好的成绩可能是因为自己的理解力吧<del>聪明？</del>所以一般别人要一小时学会的我可能半小时或者更少，但我不会去锻炼自己从而提升这个能力，导致自己应该算学习上挺被动的，但也能取得好一点的成绩吧，当然到高中加上外界压力和内部矛盾，还有日积月累的知识不深化导致现在的结果，所以不怨天不怨地的确是怨自己。好处也有吧，就是不用担心成绩的问题，啊，当然奖学金没了还是很烦的(<del>今年才弄了200</del>)，自己的时间也多一些，当然可能自己还没意识到自己的问题，所以又被导师说了。(╬▔皿▔)╯</p><p><img src="/2023/12/23/%E6%BC%AB%E8%B0%881/R.jpg" alt></p><hr><p>​    说了自己这么多，实际上更想说咱们国内的统一的问题吧，应该算。实际上，在上高中的时候我可能已经思考了大概有几年的问题，当然现在也是没有答案的。我从一个小县城到了一个大点的城市(也挺小的)，让我感触最深的便是自己与别人的差距，不是自身的而是家庭或者说叫做背景。所以我思考的问题是“读书究竟是为了什么？”有人说为了将来有一个好工作，有人说是为了开阔自己的眼界，还有人说是为了中华之崛起而读书。对我而言，我不知道，可能对于每个人答案都不一样。或者说这个问题更应该叫“学习是为了什么”，从小就一直听着父母和老师的话，学习要好，这样才能怎样怎样。可现实却是，好像是无论怎样去努力，都逃不脱这“围城”。我有点这样的无力感，别人好像不需要这样就能达到你这样子甚至是你永远达不到的高度。好像你这一辈子学习就像一个笑话。</p><p><img src="/2023/12/23/%E6%BC%AB%E8%B0%881/RC.jpg" alt></p><p>特别是到了大学之后这种感觉愈加强烈，看着学长学姐为了考研而努力，最后也只是为了求一份稳定的工作，或者说是为了温饱。很搞笑是不是。人，归根结底说还是动物，既然是动物就逃不脱生物的规则。“物竞天择，适者生存”我是敬佩达尔文先生的，当然这句话也可能是错误的,(<del>这个世界是奇妙的，现在学到的所有知识都有可能是错误的也说不定</del>),但就目前而言这是真理。（我觉得）。<img src="/2023/12/23/%E6%BC%AB%E8%B0%881/drw.jpg" alt></p><p>都是为了生存而言，所以人算神奇的动物了。<del>有点跑题了好像</del>回到我们现在的环境，就是这句话灵验的时候，虽然一直都是这样。所以为了”活“下去，只有不断提升自己，与别人竞争，也就是现在说的”卷“(反正我是不喜欢这个词的含义)当然我这个是漫谈系列所以能讲不出什么大道理，只是简单的聊天交心吧算。所以呢可能我说的话没什么逻辑，就是我想到啥说啥了，hhhh。当然之后试着开一下评论，可能想评论的话就得用魔法注册一下了。</p><hr><p>​    说了这么多，可能就当我的一个吐槽了吧，毕竟自己也是深陷其中了，无法逃离唯有顺波逐流了。所以记得那句话吧，为自己而活，那样的话将来不至于迷茫许久。</p><h2><a name="to-be-continue" class="anchor" href="#to-be-continue"><span class="header-link"></span></a>to be continue</h2>]]></content>
    
    
    <categories>
      
      <category>杂谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>从头开始</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>web学习(1)</title>
    <link href="/2023/12/20/web%E5%AD%A6%E4%B9%A0-1/"/>
    <url>/2023/12/20/web%E5%AD%A6%E4%B9%A0-1/</url>
    
    <content type="html"><![CDATA[<h1><a name="javeweb-day1" class="anchor" href="#javeweb-day1"><span class="header-link"></span></a>JaveWeb学习---------day1</h1><h2><a name="1-" class="anchor" href="#1-"><span class="header-link"></span></a>1.前言</h2><p>我们日常上网的过程中肯定会看到各种各样的网站，而这些网站的开发就是可以通过Javaweb的学习来构建自己的网站。</p><p>所谓的web开发：</p><p>web就是，网页的意思，例如<a href="http://www.baidu.com">www.baidu.com</a></p><p>而网页又分为静态和动态的，顾名思义静态就是固定的数据显示在网页上，而动态就是会随时根据用户的使用发生变化，几乎所有的网页都是动态的，在Java中，动态web资源开发的技术统称为JavaWeb；</p><h2><a name="2-" class="anchor" href="#2-"><span class="header-link"></span></a>2.开发流程</h2><p>在工作中一般是由设计师设计网页，之后交给前端工程师来开发写出对应的静态网页，最后给后端Java程序员来把静态网页修改成我们所看到的动态网页，如图s</p><p><img src="/2023/12/20/web%E5%AD%A6%E4%B9%A0-1/3.jpg" alt></p><p>（这是早些时候的开发流程，现在的话大部分是前后端分离，就是前端页面与后端程序是分别交给他们设计，根据接口文档实现前后端的交互）当然现在大部好像只会后端或者前端不能满足市场需求（除非非常厉害）好像都是要求全栈开发了，<del>最讨厌了</del></p><p>特别是现在出现的各种框架时的开发变得越来越方便，所以往底层学习是不可避免的。所以这次博客算是回顾加学习了。从最开始的web开发开始。</p><h3><a name="3-" class="anchor" href="#3-"><span class="header-link"></span></a>3.技术栈</h3><p>前端：一般是三件套</p><p>1.html</p><p>2.css</p><p>3.JavaScript</p><p>后面的vue等等框架。</p><p>后端：</p><p>javaEE:</p><p>Jsp与Servlet</p><p>Tomcat与Jetty服务器</p><p>还有后面的springboot，等等</p><p><del>所以说革命尚未成功，同志仍需努力呀</del></p><p><img src="/2023/12/20/web%E5%AD%A6%E4%B9%A0-1/885DE6412F5F1BBD7895D81052508601.jpg" alt></p><p>okok,所以说还是得继续学习，无论在哪个领域。(所以何时是尽头啊ψ(｀∇´)ψ)废话说完继续。</p><h3><a name="4-" class="anchor" href="#4-"><span class="header-link"></span></a>4.前端</h3><p>所以我们先从前端页面开始学习，首先学习三件套（三剑客）</p><p><strong>页面由三部分内容组成：分别是内容（结构）、表现、行为</strong></p><p>1.<strong>内容</strong>（结构），是我们在页面中可以看到的数据。我们称之为内容。一般内容 我们使用 html 技术来展示。</p><p>2 .<strong>表现</strong>，指的是这些内容在页面上的展示形式。比如说。布局，颜色，大小等等。一般使用 CSS 技术实现 </p><p>3.<strong>行为</strong>，指的是页面中元素与输入设备交互的响应。一般使用 javascript 技术实现</p><h4><a name="html-hyper-text-markup-language-" class="anchor" href="#html-hyper-text-markup-language-"><span class="header-link"></span></a>html——Hyper Text Markup Language （超文本标记语言）</h4><p>HTML 通过标签来标记要显示的网页中的各个部分。网页文件本身是一种文本文件， 通过在文本文件中添加标记符，可以告诉浏览器如何显示其中的内容（如：文字如何处理，画 面如何安排，图片如何显示等</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">html</span> <span class="hljs-attr">lang</span>=<span class="hljs-string">&quot;en&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">&quot;UTF-8&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;viewport&quot;</span> <span class="hljs-attr">content</span>=<span class="hljs-string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Document<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span><br>    hello<br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br></code></pre></td></tr></table></figure><p>Java 文件是需要先编译，再由 java 虚拟机跑起来。但 HTML 文件它不需要编译，直接由浏览器进行解析执行</p><p>如果想试试的话可以先下载vscode在创建一个.html文件最后在网页上可以看到hello的字段</p><p><img src="/2023/12/20/web%E5%AD%A6%E4%B9%A0-1/4.jpg" alt></p><h4><a name="html-" class="anchor" href="#html-"><span class="header-link"></span></a>html书写规范：</h4><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs html"><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">html</span> <span class="hljs-attr">lang</span>=<span class="hljs-string">&quot;en&quot;</span>&gt;</span>        -------表示整个页面的开始<br><span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span>                  -------头信息 <br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">&quot;UTF-8&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;viewport&quot;</span> <span class="hljs-attr">content</span>=<span class="hljs-string">&quot;width=device-width, initial-scale=1.0&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Document<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span> -------标题<br><span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span>                      --------页面的主体（就是给网页展示的内容）<br>    hello                   -------主体内容<br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span>                     ----------页面结束    <br><span class="hljs-comment">&lt;!-- 这是 html 注释，可以在页面右键查看源代码中看到  --&gt;</span><br></code></pre></td></tr></table></figure><p> 先写这些整理下继续</p>]]></content>
    
    
    <categories>
      
      <category>javaweb</category>
      
    </categories>
    
    
    <tags>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的第一篇博客</title>
    <link href="/2023/12/19/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <url>/2023/12/19/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<p>没错你没看错，我之前的文章全没了，所以从0开始了</p>]]></content>
    
    
    <categories>
      
      <category>杂谈</category>
      
    </categories>
    
    
    <tags>
      
      <tag>从头开始</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
